// This is an autogenerated file from Firebase Studio.
'use server';

/**
 * @fileOverview Assesses the severity of a vulnerability based on its context.
 *
 * - assessVulnerability - A function that takes vulnerability details and returns an AI-driven severity assessment.
 * - AssessVulnerabilityInput - The input type for the assessVulnerability function.
 * - AssessVulnerabilityOutput - The return type for the assessVulnerability function.
 */

import {ai} from '@/ai/genkit';
import {z} from 'genkit';

const AssessVulnerabilityInputSchema = z.object({
  vulnerability: z.string().describe('JSON string of the vulnerability object.'),
  context: z.string().describe('Context of where the vulnerability was found, e.g., "login page", "user profile form".'),
});

export type AssessVulnerabilityInput = z.infer<typeof AssessVulnerabilityInputSchema>;

const AssessVulnerabilityOutputSchema = z.object({
  assessedSeverity: z.enum(['Critical', 'High', 'Medium', 'Low']).describe('The AI-assessed severity of the vulnerability.'),
  assessmentJustification: z.string().describe('A brief justification for the assessed severity.'),
});

export type AssessVulnerabilityOutput = z.infer<typeof AssessVulnerabilityOutputSchema>;

export async function assessVulnerability(input: AssessVulnerabilityInput): Promise<AssessVulnerabilityOutput> {
  return assessVulnerabilityFlow(input);
}

const prompt = ai.definePrompt({
  name: 'assessVulnerabilityPrompt',
  input: {schema: AssessVulnerabilityInputSchema},
  output: {schema: AssessVulnerabilityOutputSchema},
  prompt: `You are a security expert. Your task is to dynamically assess the severity of a vulnerability based on its details and the context in which it was discovered.

  **Vulnerability Details:**
  {{{vulnerability}}}

  **Context:**
  Discovered on: {{{context}}}

  **Instructions:**
  1.  Analyze the vulnerability in relation to its context. For example, an XSS vulnerability on a login page is more critical than on a static 'About Us' page.
  2.  Determine the severity level: 'Critical', 'High', 'Medium', or 'Low'.
  3.  Provide a concise, one-sentence justification for your assessment.

  **Example:**
  - Input: XSS vulnerability on a search results page.
  - Output: { assessedSeverity: 'High', assessmentJustification: 'The vulnerability could be used to steal session cookies or perform actions on behalf of other users.' }
  `,
});

const assessVulnerabilityFlow = ai.defineFlow(
  {
    name: 'assessVulnerabilityFlow',
    inputSchema: AssessVulnerabilityInputSchema,
    outputSchema: AssessVulnerabilityOutputSchema,
  },
  async input => {
    const {output} = await prompt(input);
    return output!;
  }
);
